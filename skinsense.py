# -*- coding: utf-8 -*-
"""SkinSense

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CQ-YAtu3i66W0luXnNTrk4NiTrCG7eC0
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
trainingdatapro_skin_defects_acne_redness_and_bags_under_the_eyes_path = kagglehub.dataset_download('trainingdatapro/skin-defects-acne-redness-and-bags-under-the-eyes')

print('Data source import complete.')

import kagglehub

# Attempt to download the dataset
dataset_path = kagglehub.dataset_download('trainingdatapro/skin-defects-acne-redness-and-bags-under-the-eyes')

# Check the path
print(f"Dataset downloaded to: {dataset_path}")

# import pandas as pd
# import os
# from PIL import Image
# import matplotlib.pyplot as plt

# # Path to the CSV file
# csv_path = os.path.join(dataset_dir, 'skin_defects.csv')

# # Load the CSV file
# df = pd.read_csv(csv_path)

# # Base directory for images
# base_image_dir = os.path.join(dataset_dir, 'files')

# # Function to display images from CSV
# def display_images(row):
#     # Adjust the image paths to be absolute by joining with base directory
#     front_image_path = os.path.join(base_image_dir, row['front'][1:])  # remove the leading '/'
#     left_side_image_path = os.path.join(base_image_dir, row['left_side'][1:])
#     right_side_image_path = os.path.join(base_image_dir, row['right_side'][1:])

#     # Load images
#     front_img = Image.open(front_image_path)
#     left_img = Image.open(left_side_image_path)
#     right_img = Image.open(right_side_image_path)

#     # Display images
#     fig, axes = plt.subplots(1, 3, figsize=(15, 5))
#     axes[0].imshow(front_img)
#     axes[0].set_title("Front View")
#     axes[1].imshow(left_img)
#     axes[1].set_title("Left Side View")
#     axes[2].imshow(right_img)
#     axes[2].set_title("Right Side View")

#     for ax in axes:
#         ax.axis('off')  # Hide axes for better visualization

#     plt.show()

# # Display images from the first row of the dataset
# display_images(df.iloc[0])

"""# **1. Install packages**"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install torchinfo

"""# **2. Import libraries**"""

# Data handling
import pandas as pd
import numpy as np

# Data visualization
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from PIL import Image

# Preprocessing
from sklearn.model_selection import train_test_split as tts

# Torch
import torch
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader
from torchinfo import summary
from torchvision.models import vit_b_16, ViT_B_16_Weights

# Metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, classification_report

# os
import os

# OrderedDict
from collections import OrderedDict

# tqdm
from tqdm.auto import tqdm

# Path
from pathlib import Path

# random
import random

# typing
from typing import Dict, List

# warnings
import warnings
warnings.filterwarnings("ignore")

from pathlib import Path

# Correct path to the images in your downloaded dataset
IMAGE_PATH = Path("/root/.cache/kagglehub/datasets/trainingdatapro/skin-defects-acne-redness-and-bags-under-the-eyes/versions/1/files")

# List all the image files
IMAGE_PATH_LIST = list(IMAGE_PATH.glob("*/*/*.jpg"))

# Print the total number of images
print(f'Total Images = {len(IMAGE_PATH_LIST)}')

"""# **3. Load data and EDA**"""

# # Total Images
# IMAGE_PATH = Path("/kaggle/input/skin-defects-acne-redness-and-bags-under-the-eyes/files")

# IMAGE_PATH_LIST = list(IMAGE_PATH.glob("*/*/*.jpg"))

# print(f'Total Images = {len(IMAGE_PATH_LIST)}')

import os
from pathlib import Path

# Correct path to the images in your downloaded dataset
IMAGE_PATH = Path("/root/.cache/kagglehub/datasets/trainingdatapro/skin-defects-acne-redness-and-bags-under-the-eyes/versions/1/files")

# List all classes (subfolders)
classes = os.listdir(IMAGE_PATH)
classes = sorted(classes)

print("**" * 20)
print(" " * 10, f"Total Classes = {len(classes)}")
print("**" * 20)

# Count the images in each class
for c in classes:
    total_images_class = list(Path(IMAGE_PATH, c).glob("*/*.jpg"))
    print(f"* {c}: {len(total_images_class)} images")

# @title Default title text
# number of images per class.
# classes = os.listdir(IMAGE_PATH)
# classes = sorted(classes)

# print("**" * 20)
# print(" " * 10, f"Total Classes = {len(classes)}")
# print("**" * 20)

# for c in classes:
#     total_images_class = list(Path(os.path.join(IMAGE_PATH, c)).glob("*/*.jpg"))
#     print(f"* {c}: {len(total_images_class)} images")

# We view some images for each class.
NUM_IMAGES = 3

fig, ax = plt.subplots(nrows = len(classes), ncols = NUM_IMAGES, figsize = (10,15))
p = 0
for c in classes:
    total_images_class = list(Path(os.path.join(IMAGE_PATH, c)).glob("*/*.jpg"))
    images_selected = random.choices(total_images_class, k = NUM_IMAGES)

    for i,img_path in enumerate(images_selected):
        img_bgr = cv2.imread(str(img_path))
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        ax[p,i].imshow(img_rgb)
        ax[p,i].axis("off")
        ax[p,i].set_title(f"Class: {c}\nShape: {img_rgb.shape}", fontsize = 8, fontweight = "bold", color = "black")

    p += 1

fig.tight_layout()
fig.show()

"""# **4. Preprocessing**

Let's create a dataframe with two columns:

- the first **path** call will store the paths of the images.
- the second call **label** that will contain the labels of each image.
"""

images_path = [None] * len(IMAGE_PATH_LIST)
labels = [None] * len(IMAGE_PATH_LIST)

for i,image_path in enumerate(IMAGE_PATH_LIST):
    images_path[i] = image_path
    labels[i] = image_path.parent.parent.stem

df_path_and_label = pd.DataFrame({'path':images_path,
                                  'label':labels})
df_path_and_label.head()

"""Now we have to divide our dataframe into 3 parts:

- **train = 70%**
- **valid = 15%**
- **test = 15%**
"""

SEED = 123

df_train, df_rest = tts(df_path_and_label,
                        test_size = 0.3,
                        random_state = SEED,
                        stratify = df_path_and_label["label"])

df_val, df_test = tts(df_rest,
                      test_size = 0.5,
                      random_state = SEED,
                      stratify = df_rest["label"])

# We have to define the mapping of the classes to convert the labels to numbers.
label_map = dict(zip(classes, range(0, len(classes))))
label_map

# Now we define the transformations that we are going to apply.
weights = ViT_B_16_Weights.DEFAULT
auto_transforms = weights.transforms()
auto_transforms

"""Now we are going to create the **Dataset's** and **DataLoader's**.

Let's start with the **Dataset's**.
"""

class CustomDataset(Dataset):
    def __init__(self, df:pd.DataFrame, transforms, label_map:dict):
        self.df = df
        self.transforms = transforms
        self.label_map = label_map

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        df_new = self.df.copy()
        df_new = df_new.reset_index(drop = True)
        df_new["label"] = df_new["label"].map(self.label_map)
        image_path = df_new.iloc[idx, 0]
        image = Image.open(image_path).convert("RGB")
        image = self.transforms(image)
        label = df_new.iloc[idx, 1]

        return image,label

# train_dataset = CustomDataset(df_train, auto_transforms, label_map)
# valid_dataset = CustomDataset(df_val, auto_transforms, label_map)

train_dataset = CustomDataset(df_train, auto_transforms, label_map)
valid_dataset = CustomDataset(df_val, auto_transforms, label_map)

"""**DataLoader's**"""

BATCH_SIZE = 1
NUM_WORKERS = os.cpu_count()

train_dataloader = DataLoader(dataset = train_dataset,
                              batch_size = BATCH_SIZE,
                              shuffle = True,
                              num_workers = NUM_WORKERS)
valid_dataloader = DataLoader(dataset = valid_dataset,
                              batch_size = BATCH_SIZE,
                              shuffle = True,
                              num_workers = NUM_WORKERS)

# Let's visualize the dimensions of a batch.
batch_images, batch_labels = next(iter(train_dataloader))

batch_images.shape, batch_labels.shape

"""# **5. Model**"""

# GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
device

# We define the model to use with the pre-trained weights.
model = vit_b_16(weights = weights)

# Let's visualize the architecture of the model.
summary(model = model,
        input_size = [1, 3, 224, 224],
        col_names = ["input_size", "output_size", "num_params", "trainable"],
        col_width = 15,
        row_settings = ["var_names"])

"""We are going to **freeze the parameters of the conv_proj and encoder layers**."""

for param in model.conv_proj.parameters():
    param.requires_grad = False

for param in model.encoder.parameters():
    param.requires_grad = False

# Let's see if the parameters were frozen.
summary(model = model,
        input_size = [1,3,224,224],
        col_names = ["input_size", "output_size", "num_params", "trainable"],
        col_width = 15,
        row_settings = ["var_names"])

"""Great!!, the parameters were frozen.

Let's visualize the last layer which we will modify the number of **out_features**, in this case it is the **number of classes we have**.
"""

output_shape = len(classes)

model.heads = nn.Sequential(OrderedDict([('head', nn.Linear(in_features = 768,
                                                            out_features = output_shape))]))

# One last time let's take a look if the last layer was modified.
summary(model = model,
        input_size = [1,3,224,224],
        col_names = ["input_size", "output_size", "num_params", "trainable"],
        col_width = 15,
        row_settings = ["var_names"])

"""Let's define the **loss function** and the **optimizer**."""

loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr = 0.01)

"""We are going to define 3 functions for training and one to store the best model:

- **train_step**
- **save_checkpoint**
- **valid_step**
- **train**
"""

def train_step(model:torch.nn.Module,
               dataloader:torch.utils.data.DataLoader,
               loss_fn:torch.nn.Module,
               optimizer:torch.optim.Optimizer):

    model.train()

    train_loss = 0.
    train_accuracy = 0.

    for batch,(X,y) in enumerate(dataloader):
        X,y = X.to(device), y.to(device)
        optimizer.zero_grad()
        y_pred_logit = model(X)
        loss = loss_fn(y_pred_logit, y)
        train_loss += loss.item()

        loss.backward()
        optimizer.step()

        y_pred_prob = torch.softmax(y_pred_logit, dim = 1)
        y_pred_class = torch.argmax(y_pred_prob, dim = 1)
        train_accuracy += accuracy_score(y.cpu().numpy(),
                                         y_pred_class.detach().cpu().numpy())

    train_loss = train_loss/len(dataloader)
    train_accuracy = train_accuracy/len(dataloader)

    return train_loss, train_accuracy

def save_checkpoint(filename, model, loss, epoch, optimizer, metric):
    state = {"filename":filename,
             "model":model.state_dict(),
             "loss":loss,
             "epoch":epoch,
             "optimizer":optimizer.state_dict(),
             "metric":metric}

    torch.save(state, filename)

def valid_step(model:torch.nn.Module,
               dataloader:torch.utils.data.DataLoader,
               loss_fn:torch.nn.Module):

    model.eval()

    valid_loss = 0.
    valid_accuracy = 0.

    with torch.inference_mode():
        for batch,(X,y) in enumerate(dataloader):
            X,y = X.to(device), y.to(device)
            y_pred_logit = model(X)
            loss = loss_fn(y_pred_logit, y)
            valid_loss += loss.item()

            y_pred_prob = torch.softmax(y_pred_logit, dim = 1)
            y_pred_class = torch.argmax(y_pred_prob, dim = 1)

            valid_accuracy += accuracy_score(y.cpu().numpy(), y_pred_class.detach().cpu().numpy())

    valid_loss = valid_loss/len(dataloader)
    valid_accuracy = valid_accuracy/len(dataloader)

    return valid_loss, valid_accuracy

def train(model:torch.nn.Module,
          train_dataloader:torch.utils.data.DataLoader,
          valid_dataloader:torch.utils.data.DataLoader,
          loss_fn:torch.nn.Module,
          optimizer:torch.optim.Optimizer,
          epochs:int = 10):

    results = {"train_loss":[],
               "train_accuracy":[],
               "valid_loss":[],
               "valid_accuracy":[]}

    best_valid_loss = float("inf")

    for epoch in tqdm(range(epochs)):
        train_loss, train_accuracy = train_step(model = model,
                                                dataloader = train_dataloader,
                                                loss_fn = loss_fn,
                                                optimizer = optimizer)

        valid_loss, valid_accuracy = valid_step(model = model,
                                                dataloader = valid_dataloader,
                                                loss_fn = loss_fn)

        if valid_loss < best_valid_loss:
            best_valid_loss = valid_loss
            file_name = "best_model.pth"
            save_checkpoint(file_name, model, best_valid_loss, epoch, optimizer, valid_accuracy)

        print(f"Epoch: {epoch + 1} | ",
              f"Train Loss: {train_loss:.4f} | ",
              f"Train Accuracy: {train_accuracy:.4f} | ",
              f"Valid Loss: {valid_loss:.4f} | ",
              f"Valid Accuracy: {valid_accuracy:.4f}")

        results["train_loss"].append(train_loss)
        results["train_accuracy"].append(train_accuracy)
        results["valid_loss"].append(valid_loss)
        results["valid_accuracy"].append(valid_accuracy)

    return results

# Training!!!
EPOCHS = 100

torch.cuda.manual_seed(SEED)
torch.manual_seed(SEED)

MODEL_RESULTS = train(model.to(device),
                      train_dataloader,
                      valid_dataloader,
                      loss_fn,
                      optimizer,
                      EPOCHS)

# Function to plot the loss and metric during each training epoch.
def loss_metric_curve_plot(model_results:Dict[str,List[float]]):

    train_loss = model_results["train_loss"]
    valid_loss = model_results["valid_loss"]

    train_accuracy = [float(value) for value in model_results["train_accuracy"]]
    valid_accuracy = [float(value) for value in model_results["valid_accuracy"]]

    fig,axes = plt.subplots(nrows = 1, ncols = 2, figsize = (10,4))
    axes = axes.flat

    axes[0].plot(train_loss, color = "red", label = "Train")
    axes[0].plot(valid_loss, color = "blue", label = "Valid")
    axes[0].set_title("CrossEntropyLoss", fontsize = 12, fontweight = "bold", color = "black")
    axes[0].set_xlabel("Epochs", fontsize = 10, fontweight = "bold", color = "black")
    axes[0].set_ylabel("Loss", fontsize = 10, fontweight = "bold", color = "black")
    axes[0].legend()

    axes[1].plot(train_accuracy, color = "red", label = "Train")
    axes[1].plot(valid_accuracy, color = "blue", label = "Valid")
    axes[1].set_title("Metric of performance: Accuracy", fontsize = 12, fontweight = "bold", color = "black")
    axes[1].set_xlabel("Epochs", fontsize = 10, fontweight = "bold", color = "black")
    axes[1].set_ylabel("Score", fontsize = 10, fontweight = "bold", color = "black")
    axes[1].legend()

    fig.tight_layout()
    fig.show()

loss_metric_curve_plot(MODEL_RESULTS)

import os
print(os.getcwd())
os.listdir()

checkpoint_path = "/content/best_model.pth"
checkpoint = torch.load(checkpoint_path)

# # Let's load the best model.
# checkpoint_path = "/kaggle/working/best_model.pth"
# checkpoint = torch.load(checkpoint_path)

# Now let's look at the smallest loss, its metric and when it occurred.
print(f'Best Loss: {checkpoint["loss"]}')
print(f'Epoch: {checkpoint["epoch"] + 1}')
print(f'Best Metric: {checkpoint["metric"]}')

"""Well, now we have to predict the images of the test set.

- **Predictions**
"""

# First of all, we create the Dataset, DataLoader
test_dataset = CustomDataset(df_test, auto_transforms, label_map)
test_dataloader = DataLoader(dataset = test_dataset, shuffle = False, num_workers = NUM_WORKERS)

# We define the model again with its respective modification.
loaded_model = vit_b_16()

loaded_model.heads = nn.Sequential(OrderedDict([('head',nn.Linear(in_features = 768,
                                                                  out_features = output_shape))]))

loaded_model.load_state_dict(checkpoint["model"])
# torch.save(loaded_model.state_dict(), "/content/model.pth")
# from google.colab import files
# files.download("/content/model.pth")
# We now infer
loaded_model.to(device)

loaded_model.eval()

y_pred_test = []

with torch.inference_mode():
    for X,y in tqdm(test_dataloader):
        X,y = X.to(device), y.to(device)
        y_pred_logit = loaded_model(X)
        y_pred_prob = torch.softmax(y_pred_logit, dim = 1)
        y_pred_class = torch.argmax(y_pred_prob, dim = 1)
        y_pred_test.append(y_pred_class.detach().cpu())

y_pred_test = torch.cat(y_pred_test).numpy()

"""# **6. Metrics**

- **Accuracy**
"""

print(f'Accuracy = {round(accuracy_score(df_test["label"].map(label_map), y_pred_test), 4)}')

"""- **Confusion Matrix**"""

confusion_matrix_test = confusion_matrix(df_test["label"].map(label_map), y_pred_test)

fig,ax = plt.subplots(figsize = (15,4))
sns.heatmap(confusion_matrix_test,
            cmap = 'coolwarm',
            annot = True,
            annot_kws = {"fontsize":9, "fontweight":"bold"},
            linewidths = 1.2,
            linecolor = "black",
            square = True,
            xticklabels = classes,
            yticklabels = classes,
            cbar = False,
            ax = ax)
ax.set_title("Confusion Matrix Test", fontsize = 10, fontweight = "bold", color = "darkblue")
ax.tick_params('x',rotation = 90)
fig.show()

import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image

# Assuming you have a ViT model like this
from torchvision.models import vit_b_16

# Define the model (ensure it's the same architecture as during training)
output_shape = len(classes)  # Set output shape according to your class labels
model = vit_b_16()
model.heads = nn.Sequential(OrderedDict([('head', nn.Linear(in_features=768, out_features=output_shape))]))

# Load the saved state_dict
model.load_state_dict(checkpoint["model"])  # Adjust the path if needed
model.eval()  # Set model to evaluation mode

# Define the necessary transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize the image to the same input size used during training
    transforms.ToTensor(),  # Convert the image to a tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize using ImageNet's mean and std
])

# Load your image
image_path = 'eyebags7.jpg'  # Replace with your image file path
image = Image.open(image_path)

# Apply the transformations
input_image = transform(image).unsqueeze(0)  # Add batch dimension (1, 3, 224, 224)

# If you're using a GPU, move the model and input to the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
input_image = input_image.to(device)

# Get the model's output
with torch.no_grad():  # No need to track gradients during inference
    output = model(input_image)

# Apply softmax to get probabilities
probabilities = torch.softmax(output, dim=1)

# Get the predicted class index
_, predicted_class = torch.max(probabilities, 1)

# Convert the predicted class index back to a label (if you have a class list)
predicted_label = classes[predicted_class.item()]  # `classes` is your list of labels
print(f"Predicted class: {predicted_label}")

import matplotlib.pyplot as plt

# Display the image and predicted label
plt.imshow(image)
plt.title(f"Prediction: {predicted_label}")
plt.show()